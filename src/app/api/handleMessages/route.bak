import { NextResponse } from "next/server";
import { ChatService } from "@/lib/chat-service";
import fs from "fs/promises";
import path from "path";
import { Message } from "@/types/chat";
import { Character } from "@/types/character";
import { Instructions } from "@/types/instructions";
import { LLMConfig } from "@/types/llm_message";
import { generatePrompt } from "@/lib/generatePrompt";

// Function to load configuration data
async function loadConfigs() {
  const dataDir = path.join(process.cwd(), "src", "data"); // Adjust path as needed

  // Load all configuration files
  const characters: Character[] = JSON.parse(
    await fs.readFile(path.join(dataDir, "characters.json"), "utf-8")
  );
  const instructions: Instructions = JSON.parse(
    await fs.readFile(path.join(dataDir, "instructions.json"), "utf-8")
  );
  const llms: LLMConfig[] = JSON.parse(
    await fs.readFile(path.join(dataDir, "llms.json"), "utf-8")
  );

  return { characters, instructions, llms };
}

const formatMessagesForAPI = (messages: any[]): Message[] => {
  return messages.map((msg) => ({
    role: msg.role as "user" | "assistant" | "system",
    content: msg.content,
  }));
};

export async function POST(req: Request) {
  try {
    const { messages, characterId, llmId } = await req.json();

    if (!messages?.length) {
      return NextResponse.json(
        { error: "No messages provided" },
        { status: 400 }
      );
    }

    if (!process.env.OPENROUTER_API_KEY) {
      return NextResponse.json(
        { error: "API key not configured" },
        { status: 500 }
      );
    }

    // Load configurations
    const configs = await loadConfigs();

    // Find the specified character and LLM
    const character = configs.characters.find((c) => c.id === characterId);
    const llmConfig = configs.llms.find((l) => l.configId === llmId);

    if (!character) {
      return NextResponse.json(
        { error: "Character not found" },
        { status: 400 }
      );
    }

    if (!llmConfig) {
      return NextResponse.json(
        { error: "LLM configuration not found" },
        { status: 400 }
      );
    }

    // Create system prompt using the imported generatePrompt function
    const systemPrompt = generatePrompt(
      characterId,
      "3_buttons",
      configs.characters,
      [configs.instructions] // Convert single instruction to array to match function signature
    );

    // Add system prompt to messages if it's not already present
    const messagesWithSystem =
      messages[0]?.role === "system"
        ? messages
        : [{ role: "system", content: systemPrompt }, ...messages];

    const chatService = ChatService.getInstance(process.env.OPENROUTER_API_KEY);
    const formattedMessages = formatMessagesForAPI(messagesWithSystem);

    // Update chat service call with LLM configuration
    const { textStream } = await chatService.continueConversation(
      formattedMessages,
      {
        modelId: llmConfig.modelId,
        temperature: llmConfig.temperature,
        maxTokens: llmConfig.maxTokens,
      }
    );

    // Create response stream
    const stream = await createResponseStream(textStream);

    return new Response(stream, {
      headers: {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        Connection: "keep-alive",
      },
    });
  } catch (error) {
    console.error("Chat API error:", error);
    return NextResponse.json(
      {
        error: "Failed to process chat request",
        details: error instanceof Error ? error.message : String(error),
      },
      { status: 500 }
    );
  }
}

const createResponseStream = async (textStream: AsyncIterable<string>) => {
  const encoder = new TextEncoder();
  return new ReadableStream({
    async start(controller) {
      try {
        for await (const textPart of textStream) {
          const chunk = {
            id: crypto.randomUUID(),
            role: "assistant",
            content: textPart,
            createdAt: new Date(),
          };
          controller.enqueue(
            encoder.encode(`data: ${JSON.stringify(chunk)}\n\n`)
          );
        }
        controller.enqueue(encoder.encode("data: [DONE]\n\n"));
        controller.close();
      } catch (error) {
        controller.error(error);
      }
    },
  });
};
